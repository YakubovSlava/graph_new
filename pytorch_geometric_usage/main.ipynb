{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## В данном ноутбуке происходит разбор способности различных моделей различать различные публикации на определенные классы.\n",
    "\n",
    "#### Сравнение будет происходить на датасете cora\n",
    "\n",
    "---\n",
    " - 1-ая модель будет представлять из себя обычную модель бустинга\n",
    " - 2-я модель будет представлять из себя нейронную сеть с использованием граовой нейронной сети"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сначала скачаем датасет.\n",
    "Его можно скачать как с  https://graphsandnetworks.com/the-cora-dataset/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "### Считывание данных для ребер графа\n",
    "edgelist = pd.read_csv('cora_dataset/cora.cites', sep='\\t', header=None, names=['target', 'source'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "### Считывание данных для узлов графв\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  feature_names + [\"subject\"]\n",
    "node_data = pd.read_csv('cora_dataset/cora.content', sep='\\t', header=None, names=column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "### Посмотрим на данные, содержащиеся в информации об узлах"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         w_0  w_1  w_2  w_3  w_4  w_5  w_6  w_7  w_8  w_9  ...  w_1424  \\\n31336      0    0    0    0    0    0    0    0    0    0  ...       0   \n1061127    0    0    0    0    0    0    0    0    0    0  ...       0   \n1106406    0    0    0    0    0    0    0    0    0    0  ...       0   \n13195      0    0    0    0    0    0    0    0    0    0  ...       0   \n37879      0    0    0    0    0    0    0    0    0    0  ...       0   \n...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...   \n1128975    0    0    0    0    0    0    0    0    0    0  ...       0   \n1128977    0    0    0    0    0    0    0    0    0    0  ...       0   \n1128978    0    0    0    0    0    0    0    0    0    0  ...       0   \n117328     0    0    0    0    1    0    0    0    0    0  ...       0   \n24043      0    0    0    0    0    0    0    0    0    0  ...       0   \n\n         w_1425  w_1426  w_1427  w_1428  w_1429  w_1430  w_1431  w_1432  \\\n31336         0       1       0       0       0       0       0       0   \n1061127       1       0       0       0       0       0       0       0   \n1106406       0       0       0       0       0       0       0       0   \n13195         0       0       0       0       0       0       0       0   \n37879         0       0       0       0       0       0       0       0   \n...         ...     ...     ...     ...     ...     ...     ...     ...   \n1128975       0       0       0       0       0       0       0       0   \n1128977       0       0       0       0       0       0       0       0   \n1128978       0       0       0       0       0       0       0       0   \n117328        0       0       0       0       0       0       0       0   \n24043         0       0       0       0       0       0       0       0   \n\n                        subject  \n31336           Neural_Networks  \n1061127           Rule_Learning  \n1106406  Reinforcement_Learning  \n13195    Reinforcement_Learning  \n37879     Probabilistic_Methods  \n...                         ...  \n1128975      Genetic_Algorithms  \n1128977      Genetic_Algorithms  \n1128978      Genetic_Algorithms  \n117328               Case_Based  \n24043           Neural_Networks  \n\n[2708 rows x 1434 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>w_0</th>\n      <th>w_1</th>\n      <th>w_2</th>\n      <th>w_3</th>\n      <th>w_4</th>\n      <th>w_5</th>\n      <th>w_6</th>\n      <th>w_7</th>\n      <th>w_8</th>\n      <th>w_9</th>\n      <th>...</th>\n      <th>w_1424</th>\n      <th>w_1425</th>\n      <th>w_1426</th>\n      <th>w_1427</th>\n      <th>w_1428</th>\n      <th>w_1429</th>\n      <th>w_1430</th>\n      <th>w_1431</th>\n      <th>w_1432</th>\n      <th>subject</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31336</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Neural_Networks</td>\n    </tr>\n    <tr>\n      <th>1061127</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Rule_Learning</td>\n    </tr>\n    <tr>\n      <th>1106406</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Reinforcement_Learning</td>\n    </tr>\n    <tr>\n      <th>13195</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Reinforcement_Learning</td>\n    </tr>\n    <tr>\n      <th>37879</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Probabilistic_Methods</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1128975</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Genetic_Algorithms</td>\n    </tr>\n    <tr>\n      <th>1128977</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Genetic_Algorithms</td>\n    </tr>\n    <tr>\n      <th>1128978</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Genetic_Algorithms</td>\n    </tr>\n    <tr>\n      <th>117328</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Case_Based</td>\n    </tr>\n    <tr>\n      <th>24043</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Neural_Networks</td>\n    </tr>\n  </tbody>\n</table>\n<p>2708 rows × 1434 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Закодируем категорию"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_data.subject)\n",
    "node_data.subject = le.transform(node_data.subject)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Case_Based', 'Genetic_Algorithms', 'Neural_Networks',\n       'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning',\n       'Theory'], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Не зная графовую структуру цитирования публикаций, о ее содержании можно судить только по тексту. Однако некоторые темы и топики очень близки друг к другу по смыслу и текстовая информация может быть не очень очевидна для текста. Это можно продемонстровать на примере нескольких моделей."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### Для дальнейшей удобной работы с графами преименуем узлы"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def node_dict(nodes_nums):\n",
    "    values = list(range(len(nodes_nums)))\n",
    "    return dict(zip(nodes_nums, values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "edgelist.target = edgelist.target.map(node_dict(node_data.index))\n",
    "edgelist.source = edgelist.source.map(node_dict(node_data.index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "node_data.index = node_data.index.map(node_dict(node_data.index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В первую очередь разобьем все существующие узлы на трейн и тест. 25% будут с неизвестным топиком"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_nodes, test_nodes = train_test_split(node_data.index, test_size=0.25, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = node_data.loc[train_nodes].drop(columns='subject'), node_data.loc[train_nodes].subject, node_data.loc[test_nodes].drop(columns='subject'), node_data.loc[test_nodes].subject"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=5, n_estimators=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints='()', n_estimators=200,\n              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n              predictor='auto', random_state=0, reg_alpha=0, ...)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "preds = model.predict(test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        77\n",
      "           1       0.84      0.83      0.83       105\n",
      "           2       0.77      0.87      0.82       214\n",
      "           3       0.80      0.75      0.78       101\n",
      "           4       0.76      0.84      0.80        44\n",
      "           5       0.86      0.38      0.53        47\n",
      "           6       0.67      0.69      0.68        89\n",
      "\n",
      "    accuracy                           0.77       677\n",
      "   macro avg       0.78      0.72      0.74       677\n",
      "weighted avg       0.77      0.77      0.76       677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "### Построим графовую нейронную сеть для решения аналогичной задачи"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(edgelist.values.transpose(), dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "features = node_data.reset_index().sort_values('index', ascending=True).drop(columns=['index', 'subject']).values\n",
    "features = torch.tensor(features, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "target = torch.tensor(node_data.reset_index().sort_values('index', ascending=True).subject.values, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "data = Data(x=features, edge_index=edge_index, y = target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[2708, 1433], edge_index=[2, 5429], y=[2708])"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GATv2Conv\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(1433, 200)\n",
    "        self.conv2 = GATv2Conv(200, 7)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x, edge_index = x.x, x.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "train_mask = torch.tensor(node_data.index.isin(train_nodes), dtype=torch.bool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"D:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_geometric\\utils\\softmax.py\", line 41, in softmax\n    elif index is not None:\n        N = maybe_num_nodes(index, num_nodes)\n        src_max = scatter(src, index, dim, dim_size=N, reduce='max')\n                  ~~~~~~~ <--- HERE\n        src_max = src_max.index_select(dim, index)\n        out = (src - src_max).exp()\n  File \"D:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_scatter\\scatter.py\", line 160, in scatter\n        return scatter_min(src, index, dim, out, dim_size)[0]\n    elif reduce == 'max':\n        return scatter_max(src, index, dim, out, dim_size)[0]\n               ~~~~~~~~~~~ <--- HERE\n    else:\n        raise ValueError\n  File \"D:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_scatter\\scatter.py\", line 72, in scatter_max\n        out: Optional[torch.Tensor] = None,\n        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\nRuntimeError: Tensors of type TensorImpl do not have strides\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [139]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m200\u001B[39m)):\n\u001B[0;32m      2\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 3\u001B[0m     preds \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m[train_mask]\n\u001B[0;32m      4\u001B[0m     reals \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39my[train_mask]\n\u001B[0;32m      5\u001B[0m     loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()(preds, reals)\n",
      "File \u001B[1;32mD:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [136]\u001B[0m, in \u001B[0;36mModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m      8\u001B[0m     x, edge_index \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mx, x\u001B[38;5;241m.\u001B[39medge_index\n\u001B[1;32m----> 9\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[0;32m     11\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x, edge_index)\n",
      "File \u001B[1;32mD:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:235\u001B[0m, in \u001B[0;36mGATv2Conv.forward\u001B[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001B[0m\n\u001B[0;32m    229\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    230\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe usage of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_attr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd_self_loops\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    231\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimultaneously is currently not yet supported for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    232\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseTensor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m form\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    234\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[1;32m--> 235\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m                     \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    238\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:317\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    316\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 317\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmsg_kwargs)\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    319\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "File \u001B[1;32mD:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:273\u001B[0m, in \u001B[0;36mGATv2Conv.message\u001B[1;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001B[0m\n\u001B[0;32m    271\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mleaky_relu(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnegative_slope)\n\u001B[0;32m    272\u001B[0m alpha \u001B[38;5;241m=\u001B[39m (x \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39matt)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 273\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_i\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m alpha\n\u001B[0;32m    275\u001B[0m alpha \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(alpha, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"D:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_geometric\\utils\\softmax.py\", line 41, in softmax\n    elif index is not None:\n        N = maybe_num_nodes(index, num_nodes)\n        src_max = scatter(src, index, dim, dim_size=N, reduce='max')\n                  ~~~~~~~ <--- HERE\n        src_max = src_max.index_select(dim, index)\n        out = (src - src_max).exp()\n  File \"D:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_scatter\\scatter.py\", line 160, in scatter\n        return scatter_min(src, index, dim, out, dim_size)[0]\n    elif reduce == 'max':\n        return scatter_max(src, index, dim, out, dim_size)[0]\n               ~~~~~~~~~~~ <--- HERE\n    else:\n        raise ValueError\n  File \"D:\\mlp\\graph_neural_networks\\venv\\lib\\site-packages\\torch_scatter\\scatter.py\", line 72, in scatter_max\n        out: Optional[torch.Tensor] = None,\n        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\nRuntimeError: Tensors of type TensorImpl do not have strides\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(200)):\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(data)[train_mask]\n",
    "    reals = data.y[train_mask]\n",
    "    loss = torch.nn.CrossEntropyLoss()(preds, reals)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 163,  163,  163,  ..., 1887, 1902,  837],\n        [ 402,  659, 1696,  ..., 2258, 1887, 1686]])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "test_preds=  model(data)[~train_mask]\n",
    "test_y=  data.y[~train_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "pr = test_preds.argmax(axis=1).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "r = test_y.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77        77\n",
      "           1       0.92      0.90      0.91       105\n",
      "           2       0.83      0.87      0.85       214\n",
      "           3       0.80      0.84      0.82       101\n",
      "           4       0.85      0.75      0.80        44\n",
      "           5       0.89      0.66      0.76        47\n",
      "           6       0.74      0.75      0.74        89\n",
      "\n",
      "    accuracy                           0.82       677\n",
      "   macro avg       0.83      0.79      0.81       677\n",
      "weighted avg       0.82      0.82      0.82       677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(r, pr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}